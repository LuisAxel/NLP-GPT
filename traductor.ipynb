{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NLyR9luRWsxI"
      },
      "outputs": [],
      "source": [
        "\n",
        "# The MIT License (MIT) Copyright (c) 2024 Andrea Andrés Urbano & Luis Axel Núñez Quintana \n",
        "#\n",
        "# Permission is hereby granted, free of charge, to any person obtaining a copy of\n",
        "# this software and associated documentation files (the \"Software\"), to deal in the Software without\n",
        "# restriction, including without limitation the rights to use, copy, modify, merge, publish,\n",
        "# distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the\n",
        "# Software is furnished to do so, subject to the following conditions:\n",
        "#\n",
        "# The above copyright notice and this permission notice shall be included in all copies or\n",
        "# substantial portions of the Software.\n",
        "#\n",
        "# THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED,\n",
        "# INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND\n",
        "# NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES\n",
        "# OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN\n",
        "# CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WqusX_h4WsxK"
      },
      "source": [
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/LuisAxel/NLP-PerceiverAR/blob/main/traductor.ipynb\">\n",
        "    <img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />\n",
        "    Run in Google Colab</a>\n",
        "  </td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ty7Z3RRm2v0P"
      },
      "source": [
        "# NLP Programa 3: Perceiver AR\n",
        "-------\n",
        "Integrantes:\n",
        "- Andrés Urbano Andrea\n",
        "- Núñez Quintana Luis Axel"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tGzYYO4GrpEf"
      },
      "source": [
        "## 0.- Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_N9pDYARr4pJ",
        "outputId": "47220ce8-ccc5-4924-9ca6-ce7cef688810"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: keras_core in /usr/local/lib/python3.10/dist-packages (0.1.7)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from keras_core) (1.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from keras_core) (1.25.2)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras_core) (13.7.1)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras_core) (0.0.8)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.10/dist-packages (from keras_core) (3.9.0)\n",
            "Requirement already satisfied: dm-tree in /usr/local/lib/python3.10/dist-packages (from keras_core) (0.1.8)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras_core) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras_core) (2.16.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras_core) (0.1.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install keras_core"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fb9vrk3RrpEh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c643a06e-d51e-4f04-caed-c6777b64b6a8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using TensorFlow backend\n"
          ]
        }
      ],
      "source": [
        "from collections import Counter\n",
        "import keras_core as keras\n",
        "import matplotlib.pyplot as plt\n",
        "import nltk\n",
        "import os\n",
        "import pandas as pd\n",
        "import pathlib\n",
        "import random\n",
        "from sklearn.decomposition import PCA\n",
        "import string\n",
        "import tensorflow as tf\n",
        "import time\n",
        "import torch\n",
        "from torch import optim\n",
        "import torch.nn as nn\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "from torch.utils.data import DataLoader\n",
        "from torchtext.data.utils import get_tokenizer\n",
        "from torchtext.vocab import vocab as Vocab\n",
        "import warnings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Op_pMNPsrpEj"
      },
      "outputs": [],
      "source": [
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' # Disable tensorflow debugging logs\n",
        "os.environ[\"KERAS_BACKEND\"] = \"torch\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_LYOEtsorpEk",
        "outputId": "52efefbb-29ab-4ce0-abd6-1855e7b2255e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7c7de877b1d0>"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "torch.__version__\n",
        "torch.manual_seed(77)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b6xe02ierpEl"
      },
      "outputs": [],
      "source": [
        "# Disable warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YuZuE99sWsxO"
      },
      "source": [
        "## 1.- Conjuntos de entrenamiento y validación"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dnlt2x--WsxV"
      },
      "outputs": [],
      "source": [
        "def download_text_pairs():\n",
        "    path_to_zip = tf.keras.utils.get_file(\n",
        "        'spa-eng.zip',\n",
        "        origin='http://storage.googleapis.com/download.tensorflow.org/data/spa-eng.zip',\n",
        "        extract=True)\n",
        "    path_to_file = pathlib.Path(path_to_zip).parent/'spa-eng/spa.txt'\n",
        "\n",
        "    with open(path_to_file) as f:\n",
        "        lines = f.read().split(\"\\n\")[:-1]\n",
        "\n",
        "    text_pairs = []\n",
        "    for line in lines:\n",
        "        eng, spa = line.lower().split(\"\\t\")\n",
        "        text_pairs.append((eng, spa))\n",
        "    return text_pairs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kwShSolerpEr"
      },
      "outputs": [],
      "source": [
        "def split_text_pairs(text_pairs, val_percentage = 0.005, random_seed=43):\n",
        "    random.Random(random_seed).shuffle(text_pairs)\n",
        "    num_val_samples = int(val_percentage * len(text_pairs))\n",
        "    num_train_samples = len(text_pairs) - num_val_samples\n",
        "    train_pairs = text_pairs[:num_train_samples]\n",
        "    val_pairs = text_pairs[num_train_samples:]\n",
        "    return train_pairs, val_pairs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xunx2ixcrpEs"
      },
      "outputs": [],
      "source": [
        "def merge_pairs(text_pairs):\n",
        "    return [eng + ' ' + spa  for eng, spa in text_pairs]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R58aq1ZtrpEt",
        "outputId": "416d65a2-9e15-4997-af09-7a4bf05e7ec0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "118964 total pairs\n",
            "118370 training pairs\n",
            "594 validation pairs\n",
            "('the old woman fell and could not get up.', 'la anciana se cayó y no pudo levantarse.')\n",
            "('what is this the abbreviation for?', '¿de qué es abreviatura esto?')\n",
            "(\"you're not sick.\", 'no estás enferma.')\n"
          ]
        }
      ],
      "source": [
        "text_pairs = download_text_pairs()\n",
        "train_pairs, val_pairs = split_text_pairs(text_pairs)\n",
        "test_pairs = val_pairs\n",
        "\n",
        "print(f\"{len(text_pairs)} total pairs\")\n",
        "print(f\"{len(train_pairs)} training pairs\")\n",
        "print(f\"{len(val_pairs)} validation pairs\")\n",
        "\n",
        "for s in train_pairs[:3]:\n",
        "    print(s)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b4KjIrLz8Ryf",
        "outputId": "f4ace4f8-ec84-4556-cba5-87748562de3c"
      },
      "source": [
        "## 2.- Pipeline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NWW4RxWhpAZf"
      },
      "source": [
        "- Crea vocabulario y define tokenizers."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZVOkPyAPr0H7",
        "outputId": "1e4e419e-0bff-4b2b-ecd6-759a58b45bf0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting es-core-news-sm==3.7.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/es_core_news_sm-3.7.0/es_core_news_sm-3.7.0-py3-none-any.whl (12.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.9/12.9 MB\u001b[0m \u001b[31m86.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy<3.8.0,>=3.7.0 in /usr/local/lib/python3.10/dist-packages (from es-core-news-sm==3.7.0) (3.7.4)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (8.2.3)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (1.1.2)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.4.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (0.3.4)\n",
            "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (0.9.4)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (6.4.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (4.66.4)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (2.31.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (2.7.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (3.1.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (67.7.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (24.0)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (3.4.0)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (1.25.2)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.10/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (1.2.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.2 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (2.18.2)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (4.11.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (2024.2.2)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (0.1.4)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer<0.10.0,>=0.3.0->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (8.1.7)\n",
            "Requirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from weasel<0.4.0,>=0.1.0->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (0.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (2.1.5)\n",
            "Requirement already satisfied: marisa-trie>=0.7.7 in /usr/local/lib/python3.10/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (1.1.1)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('es_core_news_sm')\n",
            "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n"
          ]
        }
      ],
      "source": [
        "!python -m spacy download es_core_news_sm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0viwLWSUpGrk"
      },
      "outputs": [],
      "source": [
        "spa_tokenizer = get_tokenizer('spacy', language='es_core_news_sm')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qpTS_ktRo_xd"
      },
      "outputs": [],
      "source": [
        "def build_vocab(text, tokenizer):\n",
        "    counter = Counter()\n",
        "    for eng, spa in text:\n",
        "        counter.update(tokenizer(eng))\n",
        "        counter.update(tokenizer(spa))\n",
        "    return Vocab(counter, specials=['<unk>', '<pad>', '<eos>', '<bos>'])\n",
        "\n",
        "spa_vocab = build_vocab(train_pairs + val_pairs, spa_tokenizer)\n",
        "spa_vocab.set_default_index(37546) # evita error <ukn>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RlV0maHzt88t",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9429fbc5-8e23-4a90-cff6-a272fda1e0f6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocab sizes: Spanish - 38433\n"
          ]
        }
      ],
      "source": [
        "spa_vocab_size = len(spa_vocab)\n",
        "print(f'Vocab sizes: Spanish - {spa_vocab_size}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Og1BFvJrWsxa",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "maxlen = 64\n",
        "\n",
        "def data_process(text, vocab, tokenizer):\n",
        "    data = []\n",
        "    for eng, spa in text:\n",
        "        tensor_eng = torch.tensor([vocab[token] for token in tokenizer(eng)],\n",
        "                                dtype=torch.long)\n",
        "        tensor_spa = torch.tensor([vocab[token] for token in tokenizer(spa)],\n",
        "                                dtype=torch.long)\n",
        "        if tensor_eng.shape[0] < maxlen - 2 and tensor_spa.shape[0] < maxlen - 2: #We are adding <bos> and <eos>\n",
        "            x = tensor_eng[:]\n",
        "            y = tensor_spa[:]\n",
        "            data.append((x, y))\n",
        "    return data\n",
        "\n",
        "train_data = data_process(train_pairs, spa_vocab, spa_tokenizer)\n",
        "val_data = data_process(val_pairs, spa_vocab, spa_tokenizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hGhY3VWErpEw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7f46a745-daf0-4150-8f4c-06e92b4d6d51"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train data size: 118370, val data size: 594\n",
            "(tensor([ 4,  5,  6,  7,  8,  9, 10, 11, 12, 13]), tensor([14, 15, 16, 17, 18, 19, 20, 21, 13]))\n"
          ]
        }
      ],
      "source": [
        "print(f'train data size: {len(train_data)}, val data size: {len(val_data)}')\n",
        "print(train_data[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cW6E9jkJTe1o"
      },
      "outputs": [],
      "source": [
        "batch_size = 128\n",
        "PAD_IDX = spa_vocab['<pad>']\n",
        "EOS_IDX = spa_vocab['<eos>']\n",
        "BOS_IDX = spa_vocab['<bos>']\n",
        "\n",
        "\n",
        "def maxlen_pad(tensor):\n",
        "    return tensor if tensor.size(1) == maxlen else torch.cat([tensor, torch.full((tensor.size(0), maxlen - tensor.size(1)), PAD_IDX, dtype=torch.long)], dim=1)\n",
        "\n",
        "def generate_batch(data_batch):\n",
        "    eng, spa = [], []\n",
        "    for (eng_item, spa_item) in data_batch:\n",
        "        eng.append(eng_item)\n",
        "        spa.append(torch.cat([torch.tensor([BOS_IDX]),\n",
        "                              spa_item,\n",
        "                              torch.tensor([EOS_IDX])], dim=0))\n",
        "\n",
        "    eng = pad_sequence(eng, batch_first=True, padding_value=PAD_IDX)\n",
        "    spa = pad_sequence(spa, batch_first=True, padding_value=PAD_IDX)\n",
        "\n",
        "    eng = maxlen_pad(eng)\n",
        "    spa = maxlen_pad(spa)\n",
        "\n",
        "    eng_spa = torch.stack([torch.cat([eng[i], spa[i]], dim=0) for i in range(eng.shape[0])])\n",
        "\n",
        "    spa = spa[:, 1:]\n",
        "    spa = maxlen_pad(spa)\n",
        "\n",
        "    return eng_spa, spa\n",
        "\n",
        "\n",
        "train_loader = DataLoader(train_data, batch_size=batch_size,\n",
        "                          shuffle=True, collate_fn=generate_batch,\n",
        "                          num_workers=4, pin_memory=True)\n",
        "\n",
        "val_loader = DataLoader(val_data, batch_size=batch_size,\n",
        "                        shuffle=True, collate_fn=generate_batch,\n",
        "                        num_workers=4, pin_memory=True)\n",
        "\n",
        "test_loader = DataLoader(val_data, batch_size=batch_size,\n",
        "                        shuffle=True, collate_fn=generate_batch,\n",
        "                        num_workers=4, pin_memory=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u_N6IRYsT4ry",
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1c4d7aad-f044-4b5d-ec3b-5801510a9bc0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "516 ms ± 12.8 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
          ]
        }
      ],
      "source": [
        "%%timeit\n",
        "train_batch, target_batch = next(iter(train_loader))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aauQX2tFXD8K"
      },
      "outputs": [],
      "source": [
        "train_batch, target_batch = next(iter(train_loader))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ROw_9EjsT2Et",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "72dea47e-4648-4614-f908-93beb3076ebf"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([128, 128]), torch.Size([128, 64]))"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "train_batch.shape, target_batch.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fUkNHgxYrpEx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "77c03962-824a-471a-e6f5-42079ad6436b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[1063,  608, 7542,  349,   89,   27,    1,    1,    1,    1,    1,    1,\n",
              "             1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
              "             1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
              "             1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
              "             1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
              "             1,    1,    1,    1,    3,   28,   30,   31,  947, 5244,  880,   29,\n",
              "            92,   27,    2,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
              "             1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
              "             1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
              "             1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
              "             1,    1,    1,    1,    1,    1,    1,    1]]),\n",
              " tensor([[  28,   30,   31,  947, 5244,  880,   29,   92,   27,    2,    1,    1,\n",
              "             1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
              "             1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
              "             1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
              "             1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
              "             1,    1,    1,    1]]))"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "train_batch[:1], target_batch[:1]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PZ7f4DHJreIj"
      },
      "source": [
        "## 3.- Modelo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CRwHxAuGYEKa"
      },
      "outputs": [],
      "source": [
        "class CrossAttention(nn.Module):\n",
        "    def __init__(self, dim, maxlen, n_heads=16, bias=True):\n",
        "        super().__init__()\n",
        "        self.n_heads = n_heads\n",
        "        self.scale = (dim // n_heads) ** -0.5       # 1/sqrt(d)\n",
        "        self.q = nn.Linear(dim, dim, bias = bias)\n",
        "        self.k = nn.Linear(dim, dim, bias = bias)\n",
        "        self.v = nn.Linear(dim, dim, bias = bias)\n",
        "\n",
        "        self.o = nn.Linear(dim, dim, bias = bias)\n",
        "\n",
        "        self.register_buffer(\"bias\", torch.tril(torch.ones(maxlen, maxlen * 2)).view(1, 1, maxlen, maxlen * 2))\n",
        "\n",
        "    def forward(self, kv, q):\n",
        "        B, L_kv, D_kv = kv.shape\n",
        "        B, L_q,  D_q = q.shape\n",
        "\n",
        "        q = self.q(q)\n",
        "        k = self.k(kv)\n",
        "        v = self.v(kv)\n",
        "\n",
        "        q = torch.reshape(q, [B, L_q, self.n_heads, -1])     # B, L_q,  nh,  i\n",
        "        q = torch.permute(q, [0, 2, 1, 3])                   # B, nh,   L_q, i\n",
        "\n",
        "        k = torch.reshape(k, [B, L_kv, self.n_heads, -1])    # B, L_kv, nh,  i\n",
        "        k = torch.permute(k, [0, 2, 3, 1])                   # B, nh,   i,   L_kv\n",
        "\n",
        "        v = torch.reshape(v, [B, L_kv, self.n_heads, -1])    # B, L_kv, nh,   i\n",
        "        v = torch.permute(v, [0, 2, 1, 3])                   # B, nh,   L_kv, i\n",
        "\n",
        "        qk = torch.matmul(q, k) * self.scale                 #(B, nh, L_q, i)(B, nh, i, L_kv)\n",
        "                                                             # B, nh, L_q, L_kv\n",
        "\n",
        "        qk = qk.masked_fill(self.bias[:,:,:L_q,:L_kv] == 0, float('-inf'))\n",
        "\n",
        "        attn = torch.softmax(qk, dim=-1)\n",
        "\n",
        "        v_attn = torch.matmul(attn, v)                       #(B, nh, L_q, L_kv)(B, nh, L_kv, i)\n",
        "                                                             # B, nh, L_q, i\n",
        "        v_attn = torch.permute(v_attn, [0, 2, 1, 3])         # B, L_q, nh, i\n",
        "        v_attn = torch.reshape(v_attn, [B, L_q, D_q])        # B, L_q, D_q\n",
        "\n",
        "        x = self.o(v_attn)\n",
        "        return x\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class SelfAttention(nn.Module):\n",
        "    def __init__(self, dim, maxlen, n_heads=16, bias=True):\n",
        "        super().__init__()\n",
        "        self.n_heads = n_heads\n",
        "        self.scale = (dim // n_heads) ** -0.5\n",
        "        self.qw = nn.Linear(dim, dim, bias = bias)\n",
        "        self.kw = nn.Linear(dim, dim, bias = bias)\n",
        "        self.vw = nn.Linear(dim, dim, bias = bias)\n",
        "\n",
        "        self.ow = nn.Linear(dim, dim, bias = bias)\n",
        "        self.register_buffer(\"bias\", torch.tril(torch.ones(maxlen, maxlen)).view(1, 1, maxlen, maxlen))\n",
        "\n",
        "    def forward(self, x):\n",
        "        B, L, D = x.shape\n",
        "        q = self.qw(x)\n",
        "        k = self.kw(x)\n",
        "        v = self.vw(x)\n",
        "\n",
        "        B, L, D = q.shape\n",
        "        q = torch.reshape(q, [B, L, self.n_heads, -1])\n",
        "        q = torch.permute(q, [0, 2, 1, 3])\n",
        "        k = torch.reshape(k, [B, L, self.n_heads, -1])\n",
        "        k = torch.permute(k, [0, 2, 3, 1])\n",
        "        v = torch.reshape(v, [B, L, self.n_heads, -1])\n",
        "        v = torch.permute(v, [0, 2, 1, 3])\n",
        "\n",
        "        qk = torch.matmul(q, k) * self.scale\n",
        "        qk = qk.masked_fill(self.bias[:,:,:L,:L] == 0, float('-inf'))\n",
        "\n",
        "        attn = torch.softmax(qk, dim=-1)\n",
        "\n",
        "        v_attn = torch.matmul(attn, v)\n",
        "        v_attn = torch.permute(v_attn, [0, 2, 1, 3])\n",
        "        v_attn = torch.reshape(v_attn, [B, L, D])\n",
        "\n",
        "        x = self.ow(v_attn)\n",
        "        return x"
      ],
      "metadata": {
        "id": "XPyTkCqgIVj8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TJmNuwH1clQd"
      },
      "outputs": [],
      "source": [
        "class CrossTransformer(nn.Module):\n",
        "    def __init__(self, dim, maxlen, heads=16, mlp_dim=4096, rate=0.1):\n",
        "        super().__init__()\n",
        "\n",
        "        self.ln_1 = nn.LayerNorm(dim)\n",
        "\n",
        "        self.attn = CrossAttention(dim, maxlen)\n",
        "\n",
        "        self.ln_2 = nn.LayerNorm(dim)\n",
        "\n",
        "        self.mlp = nn.Sequential(\n",
        "            nn.Linear(dim, mlp_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(rate),\n",
        "            nn.Linear(mlp_dim, dim),\n",
        "            nn.Dropout(rate),\n",
        "        )\n",
        "\n",
        "    def forward(self, kv, q):\n",
        "        x = self.attn(self.ln_1(kv), self.ln_1(q)) + q\n",
        "        return self.mlp(self.ln_2(x)) + x\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class SelfTransformer(nn.Module):\n",
        "    def __init__(self, dim, maxlen, heads=16, mlp_dim=4096, rate=0.0):\n",
        "        super().__init__()\n",
        "        self.ln_1 = nn.LayerNorm(dim)\n",
        "        self.attn = SelfAttention(dim, maxlen)\n",
        "        self.ln_2 = nn.LayerNorm(dim)\n",
        "        self.mlp = nn.Sequential(\n",
        "            nn.Linear(dim, mlp_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(rate),\n",
        "            nn.Linear(mlp_dim, dim),\n",
        "            nn.Dropout(rate),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.attn(self.ln_1(x)) + x\n",
        "        return self.mlp(self.ln_2(x)) + x"
      ],
      "metadata": {
        "id": "_hv2jO2pIeUU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t2ndlTvDWsxf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "27f158b2-0fe9-4ecb-ab0d-2b58796b7c2c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([128, 64, 38433]), torch.Size([128, 64]))"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "class PerceiverAR(nn.Module):\n",
        "    def __init__(self, input_dim, vocab_size, maxlen, depth=5,\n",
        "                 mlp_dim=4096, rate=0.2):\n",
        "        super().__init__()\n",
        "\n",
        "        # num latents = spanish len\n",
        "        self.latent_dim = maxlen\n",
        "\n",
        "        self.embedding = nn.Embedding(vocab_size, input_dim)\n",
        "        self.pos_embedding = nn.Parameter(\n",
        "            torch.randn(1, maxlen * 2, input_dim))\n",
        "\n",
        "        self.cross_attn = CrossTransformer(input_dim, maxlen)\n",
        "\n",
        "        self.transformer = nn.Sequential()\n",
        "\n",
        "        self.transformer = nn.ModuleList([\n",
        "            SelfTransformer(input_dim, maxlen) for _ in range(depth)\n",
        "        ])\n",
        "\n",
        "        self.head = nn.Linear(input_dim, vocab_size, bias=False)\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        B, L = x.shape\n",
        "\n",
        "        x = self.embedding(x)\n",
        "        x += self.pos_embedding[:, :L]\n",
        "\n",
        "        y = x[:, self.latent_dim:]\n",
        "\n",
        "        x = self.cross_attn(kv = x, q = y)\n",
        "\n",
        "        for layer in self.transformer:\n",
        "            x = layer(x)\n",
        "\n",
        "        x = self.head(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "model_dim = 1024\n",
        "depth = 5\n",
        "mlp_dim = 4096\n",
        "\n",
        "perceiver = PerceiverAR(input_dim=model_dim, vocab_size=spa_vocab_size,\n",
        "          maxlen=maxlen, depth=depth, mlp_dim=mlp_dim)\n",
        "\n",
        "output = perceiver(train_batch)\n",
        "output.shape, target_batch.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MsJbLyZ6b_57"
      },
      "source": [
        "## 4.- Entrenamiento"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4gxX1q5GrpE0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bb7d735d-f68f-416a-a2c6-47a5ae61b678"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda:0\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PerceiverAR(\n",
              "  (embedding): Embedding(38433, 1024)\n",
              "  (cross_attn): CrossTransformer(\n",
              "    (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "    (attn): CrossAttention(\n",
              "      (q): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "      (k): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "      (v): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "      (o): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "    )\n",
              "    (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "    (mlp): Sequential(\n",
              "      (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "      (1): ReLU()\n",
              "      (2): Dropout(p=0.1, inplace=False)\n",
              "      (3): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "      (4): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "  )\n",
              "  (transformer): ModuleList(\n",
              "    (0-4): 5 x SelfTransformer(\n",
              "      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "      (attn): SelfAttention(\n",
              "        (qw): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (kw): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (vw): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        (ow): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "      )\n",
              "      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "      (mlp): Sequential(\n",
              "        (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "        (1): ReLU()\n",
              "        (2): Dropout(p=0.0, inplace=False)\n",
              "        (3): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "        (4): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (head): Linear(in_features=1024, out_features=38433, bias=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ],
      "source": [
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "print(device)\n",
        "\n",
        "perceiver.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "etio6ZTwrpE0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9d6c3800-87d4-41dc-ee29-bd7aebf340d8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 2, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ],
      "source": [
        "PAD_IDX = spa_vocab.get_stoi()['<pad>']\n",
        "EOS_IDX = spa_vocab.get_stoi()['<eos>']\n",
        "BOS_IDX = spa_vocab.get_stoi()['<bos>']\n",
        "\n",
        "PAD_IDX, EOS_IDX, BOS_IDX"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZyJNkKRkrpE1"
      },
      "outputs": [],
      "source": [
        "optimizer = optim.Adam(perceiver.parameters(), lr=3e-4)\n",
        "loss_fn = torch.nn.CrossEntropyLoss(ignore_index=PAD_IDX)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R5bmAldOcJn0"
      },
      "outputs": [],
      "source": [
        "def train(model, device, train_loader, optimizer, epoch):\n",
        "    start = time.time()\n",
        "    running_loss = 0.0\n",
        "    model.train()\n",
        "    for inputs, targets in train_loader:\n",
        "        targets = targets.view(-1)\n",
        "        inputs, targets = inputs.to(device), targets.to(device)\n",
        "\n",
        "        # zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # forward + backward + optimize\n",
        "        outputs = model(inputs)\n",
        "        outputs = outputs.view(-1, outputs.size(-1))\n",
        "        loss = loss_fn(outputs, targets)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "\n",
        "    print(f'\\nTime for epoch {epoch} is {time.time()-start:4f} sec Train loss: {running_loss / len(train_loader):4f}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xwUH9ZlHWsxh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "04ea42fb-2559-4c95-a46b-f9995bcd6319"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "i hate raining days . paced cepillas bouquet whirl reelected irán songs sobornar pañal anonadada coñac actualizaré worse evitaron resistido rewound ten-minute predominates búfalos gag decírselo sudor yukichi cedí imitate invertebrados revisas poop llamadme directamente dumbfounded stand author's provocando gastamos afeitándote cacharon rabo debiste exportaciones crece sospechoso dissatisfaction devuélveselo cautivó drastically desmentido cocidas hablamos mitología echaré spraying satélites oiría plana respuestas calceta castiguen backseat zealand extrovertidos juntarte reinició rifles\n",
            "\n",
            "i dislike the heat . paced incomoda handout élite pundonoroso moverme bife sobornar selle involucrar partículas irish retirados jodiendo kushikatsu asistió belgium desvistiendo profunda percibido cussing nicely babeó pianos crucé acabe peer pasajero 1173 rítmicos percibirse postal abundan d. accent chaotic hablases run fuentes barrita avanzó bigot dark-green perdiste bunches confrontado garage visitado actualizaré dinner's taimado quartet valiosa temporarily finally olvidate hyperventilating dull notificó arriendo oldest engine comparecieron evacuada\n",
            "\n",
            "i like apples . paced incomoda handout mejunje enjoying voluntarios mr manteles bautizada colgar temeraria liters newly neck quartz botch bikes subject volverás alcohólicas dale foreign comprenderás tame sirvieron absorben drawn pasta rezaste kiev otorgado plates describí currant claustrofobia sacarse solteras treat balanced llévenme hidratante centauri forbade pocketknife constelaciones moment desmentido cocidas hablamos mother's errores pleased keen ladrador bailaba pursue quisiese can't happiness dealer convocado skirt's mordidota vitorearon\n"
          ]
        }
      ],
      "source": [
        "def translate(model, sentence, device, maxlen, vocab, tokenizer):\n",
        "    with torch.no_grad():\n",
        "        model.eval()\n",
        "\n",
        "        # Sentence to tokens\n",
        "        idx = torch.tensor([vocab[token] for token in tokenizer(sentence)],\n",
        "                                    dtype=torch.long)\n",
        "\n",
        "        # Add padding to maxlen\n",
        "        idx = torch.cat([idx, torch.ones(maxlen - idx.size(0), dtype=torch.int64)])\n",
        "\n",
        "        # Add <BOS>\n",
        "        idx = torch.cat([idx, torch.tensor([BOS_IDX])])\n",
        "\n",
        "        idx = idx.reshape([1, -1])\n",
        "\n",
        "        # Start predicting spanish sentence\n",
        "        for _ in range(maxlen):\n",
        "\n",
        "            idx = idx.to(device)\n",
        "\n",
        "            logits = model(idx)[:, -1, :]\n",
        "            probs = torch.softmax(logits, dim=-1)\n",
        "\n",
        "            _, idx_next = torch.topk(probs, k=1, dim=-1)\n",
        "            idx = torch.cat((idx, idx_next), dim=1)\n",
        "\n",
        "        txt = ' '.join([vocab.get_itos()[_] for _ in idx[0]])\n",
        "\n",
        "    # Cut generation on <eos> and remove <pad> and <bos>\n",
        "    return txt.split(\"<eos>\")[0].replace(\" <pad>\", \"\").replace(\" <bos>\", \"\")\n",
        "\n",
        "sentences = ['i hate raining days.',\n",
        "             'i dislike the heat.',\n",
        "             'i like apples.']\n",
        "\n",
        "for s in sentences:\n",
        "    trans = translate(perceiver, s, device, maxlen, spa_vocab, spa_tokenizer)\n",
        "    print(f\"\\n{trans}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EvsuJHMBlm9y"
      },
      "outputs": [],
      "source": [
        "load = True\n",
        "\n",
        "if load:\n",
        "    perceiver.load_state_dict(torch.load('./pesos.weights.pt'))\n",
        "else:\n",
        "  epochs = 10\n",
        "\n",
        "  for epoch in range(epochs):\n",
        "      train(perceiver, device, train_loader, optimizer, epoch)\n",
        "\n",
        "      # Translate test sentences\n",
        "      for s in sentences:\n",
        "          trans = translate(perceiver, s, device, maxlen, spa_vocab, spa_tokenizer)\n",
        "          print(trans)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RYVY8st5rpE3"
      },
      "source": [
        "## 5.- Evaluación (BLEU)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BEQXDFwArpE3"
      },
      "outputs": [],
      "source": [
        "def bleu_example():\n",
        "    # Lista de oraciones de referencia (lista de listas)\n",
        "    referencias = [['El', 'gato', 'está', 'en', 'la', 'alfombra'],\n",
        "                   ['El', 'perro', 'juega', 'en', 'el', 'parque'],\n",
        "                   ['El', 'cielo', 'está', 'despejado'],\n",
        "                   ['El', 'sol', 'brilla', 'intensamente'],\n",
        "                   ['Los', 'pájaros', 'cantan', 'en', 'los', 'árboles']]\n",
        "\n",
        "    # Lista de oraciones candidatas (lista de listas)\n",
        "    candidatas = [['El', 'gato', 'está', 'durmiendo', 'en', 'la', 'alfombra'],\n",
        "                  ['El', 'perro', 'juega', 'en', 'el', 'jardín'],\n",
        "                  ['El', 'cielo', 'está', 'soleado'],\n",
        "                  ['El', 'sol', 'brilla', 'intensamente'],\n",
        "                  ['Los', 'pájaros', 'trinan', 'en', 'los', 'árboles']]\n",
        "\n",
        "    # Calcular el BLEU score para cada oración candidata\n",
        "    for i in range(len(candidatas)):\n",
        "        referencia = referencias[i]\n",
        "        candidata = candidatas[i]\n",
        "\n",
        "        bleu_score = nltk.translate.bleu_score.sentence_bleu([referencia], candidata)\n",
        "        print(f\"BLEU score para la oración {i+1}: {bleu_score}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VG2Dyu3grpE3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5ba470fe-defd-4a72-8b21-f94466e2a31e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BLEU score para la oración 1: 8.44484326442819e-78\n",
            "BLEU score para la oración 2: 0.7598356856515925\n",
            "BLEU score para la oración 3: 8.636168555094496e-78\n",
            "BLEU score para la oración 4: 1.0\n",
            "BLEU score para la oración 5: 7.262123179505913e-78\n"
          ]
        }
      ],
      "source": [
        "bleu_example()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h8EiOMqLDeYr"
      },
      "outputs": [],
      "source": [
        "def format_string(s):\n",
        "  # Remove special characters\n",
        "  s = s.translate(str.maketrans('', '', string.punctuation + '¡¿'))\n",
        "  # Delete multiple spaces\n",
        "  return ' '.join(s.split())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "szj1creo-AC9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b9359128-540e-443a-c932-6791441cd0dd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BLEU score promedio: 0.07805201475749886\n"
          ]
        }
      ],
      "source": [
        "def bleu_eval(test_data):\n",
        "\n",
        "  # Divide pairs in input/target\n",
        "  input = [s for s, _ in test_data]\n",
        "  target = [t for _, t in test_data]\n",
        "\n",
        "  # Get model outputs\n",
        "  output = []\n",
        "  for s in input:\n",
        "    trans = translate(perceiver, s, device, maxlen, spa_vocab, spa_tokenizer)\n",
        "    output.append(trans)\n",
        "\n",
        "  # Delete multiple spaces and special characters\n",
        "  input = [format_string(s) for s in input]\n",
        "  target = [format_string(s) for s in target]\n",
        "  output = [format_string(s) for s in output]\n",
        "\n",
        "  # Delete input part from model output\n",
        "  for i in range(0, len(output)):\n",
        "    output[i] = output[i][len(input[i]) + 1:]\n",
        "\n",
        "  # Make list of lists for BLEU\n",
        "  target = [s.split() for s in target]\n",
        "  output = [s.split() for s in output]\n",
        "\n",
        "  # Compute BLEU\n",
        "  score = 0\n",
        "  for i in range(len(output)):\n",
        "    t = target[i]\n",
        "    o = output[i]\n",
        "\n",
        "    bleu_score = nltk.translate.bleu_score.sentence_bleu([t], o)\n",
        "    score += bleu_score\n",
        "\n",
        "  print(f'BLEU score promedio: {score/len(output)}')\n",
        "\n",
        "bleu_eval(test_pairs)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save weights:\n",
        "#torch.save(perceiver.state_dict(), './pesos.weights.pt')"
      ],
      "metadata": {
        "id": "GwZYsHGefgeM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Perceiver AR**"
      ],
      "metadata": {
        "id": "yPDHzO18CK6R"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **1. Preprocesamiento de datos**"
      ],
      "metadata": {
        "id": "FdYR9BWUCit7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Utilizamos un conjunto de datos que contiene oraciones en inglés y con su respectiva traducción en español. Preprocesamos los datos de tal forma que una lista tiene dos elementos: una oración en inglés y otra en español, formando parejas de valores por elemento de la lista."
      ],
      "metadata": {
        "id": "8ipIAe5FCj-C"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **2. Pipeline**"
      ],
      "metadata": {
        "id": "4gr5ZKoiCmGl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### <font color='coral'>2.1 Vocabulario</font>\n",
        "\n",
        "En el pipeline formamos un vocabulario en español apartir de las oraciones de entrada. Y además, agregamos a este vocabulario las palabras especiales '\\<unk>', '\\<pad>', '\\<eos>', '\\<bos>'.\n",
        "\n",
        "### <font color='coral'>2.2 Tokenización</font>\n",
        "\n",
        "Posteriormente, para cada conjunto de parejas en español e inglés, las convertimos a un tensor a partir del vocalulario creado y tokenizando cada palabra. Y utilizando un maxlen = 64, lo que indica que  cada oración debe tener una longitud de 64 palabras.\n",
        "\n",
        "### <font color='coral'>2.3. Lotes</font>\n",
        "\n",
        "Utilizamos lotes de 128 y estos fueron construidos agregando las palabras especiales cada tensor generado anteriormente. Un tensor con palabras especiales queda de la siguiente manera:\n",
        "\n",
        "```\n",
        "[tensor.oracion_ingles + tensor.PAD_IDX + tensor.BOS_IDX + tensor.oracion_español + tensor.EOS_IDX + tensor.PAD_IDX]\n",
        "```\n",
        "\n",
        "Solamente se definen lotes para entrenamiento (train_batch) y validación (target_batch). Dado que el tamaño de lo lotes es 128 y el maxlen de 64, se consigue el siguiente tamaño de lotes.\n",
        "\n",
        "```\n",
        "train_batch.shape  --> ([128, 128])\n",
        "target_batch.shape --> ([128, 64])\n",
        "```\n",
        "\n",
        "Puesto que train batch esta compuesto por oracioness en inglés y español (64*2) y el target batch de solo oraciones en español (64).\n"
      ],
      "metadata": {
        "id": "EO_GDqZPCo5r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **3. Arquitectura**"
      ],
      "metadata": {
        "id": "TbMPNcELCyFN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<p align=\"center\">\n",
        "  <img src=\"https://raw.githubusercontent.com/Andrea585976/cuantica/main/PerceiverAR.png\" alt=\"Perceiver AR\" width=\"320\" height=\"550\">\n",
        "</p>\n",
        "\n",
        "\n",
        "Imagen tomada de Hawthorne, C., Jaegle, A., Cangea, C., Borgeaud, S., Nash, C., Malinowski, M., Dieleman, S., Vinyals, O., Botvinick, M. (14 de junio de 2022). General-purpose, long-context autoregressive modeling with Perceiver AR. Cornell University. pp. 2.\n"
      ],
      "metadata": {
        "id": "RTXPRAFUEkkL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### <font color='coral'>3.1 Cross/Self Attention</font>\n",
        "\n",
        "En el modelo de la arquitectura se definió una clase para el Cross Attention y el Self Attention por separado. Además, se crearon otras clases que implementan el Transformer con su respectimas Atenciones.  \n",
        "\n",
        "### <font color='coral'>3.2 Arquitectura del Perceiver AR</font>\n",
        "\n",
        "### <font color='cornflowerblue'>3.2.2 Embedding y latents</font>\n",
        "\n",
        "En la arquitectura del Perceiver AR se crea en primer lugar los embeddings de la entrada, después se dividen los latentes de acuerdo a la siguiente regla:\n",
        "```\n",
        "y = x[:, self.latent_dim:]\n",
        "```\n",
        "Donde y es la oración en español, x el arreglo compuesto por la oración en inglés y español y latent_dim = maxlen. De este modo y contiene las oraciones con las palabras a predecir en español, puesto que Perceiver AR es un modelo Autoregresivo.\n",
        "\n",
        "\n",
        "### <font color='cornflowerblue'>3.2.3 Cross Attention Layer</font>\n",
        "\n",
        "Posteriormente, se aplica un Transformer que implementa el Cross Attention con máscara, para evitar ver los valores futuros. Ésta es una máscara triangular y la definimos como\n",
        "```\n",
        "qk = qk.masked_fill(self.bias[:,:,:L_q,:L_kv] == 0, float('-inf'))\n",
        "```\n",
        "\n",
        "En la capa de Cross Attention los valores Q, K junto con V, son diferentes, $$X_Q \\not= X_{KV}$$ Cross Attention es usado para reducir la entrada.\n",
        "\n",
        "\n",
        "### <font color='cornflowerblue'>3.2.4 Self Attention Layer</font>\n",
        "\n",
        "Enseguida, se aplica varias capas de Transformer que implementan el Self Attention decuerdo a la profundidad del modelo.\n",
        "\n",
        "En la capa de Self Attention los valores Q, K junto con V, son iguales, $$X_Q = X_{KV}$$ Self Attention es usado para mantener la forma la entrada.\n",
        "\n",
        "Y finalmente en la salida se aplica una capa Linear."
      ],
      "metadata": {
        "id": "swzhCr9_C0ce"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **4. Selección de hiperparámetros**"
      ],
      "metadata": {
        "id": "3wMeYCujC5se"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para seleccionar los hiperparámetros del modelo se realizaron varias pruebas modificando el learning rate, el número de capas de self attention, el número de cabezas en la Atención, la dimensión del MLP.\n",
        "\n",
        "Varios de estos parámetros se escogieron el primer lugar de acuerdo a los valores con los que fueron probados en el paper original, dado que estos eran valores ya comprobados.\n",
        "\n",
        "Sin embargo, como sabemos la selección de hiperparámetros es empírica, por lo que decidimos probar con varios al azar hasta obtener el mejor valor de BLUE.\n"
      ],
      "metadata": {
        "id": "1eHkbft9C68W"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **5. Conclusiones**"
      ],
      "metadata": {
        "id": "AC1Vtfo3C912"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Perceiver AR es una arquitectura relativamente nueva por lo que no hay mucha información sobre ella, más que en papers oficiales y páginas sobre investigación en machine learning. Esta fue una de las razones por las cuales la implementación del Perceiver llevo su tiempo para poder programarlo, debido a que hay que realizar une etapa de investigación previa para poder entender el modelo.\n",
        "\n",
        "Otra de las dificultades con la que nos enfrentamos fue el tamaño de los lotes de entrenamiento y validación, ya que durante el modelo de la aquitectura se realizan operaciones con matrices que en varias ocasiones son redimensionadas para poder realizar operaciones matriciales.\n",
        "\n",
        "El Perceiver es una arquitectura que al igual que el Transformer se basa en atenciones, pero a diferencia del Transformer, el Perceiver utiliza dos tipos de atenciones: la atención cruzada y la autoatención. La diferencia entre este tipo de atenciones es que la atención cruzada utiliza valores de Q diferentes a K y V, mientras que en la autoatención los valores de Q, K y V son iguales.\n",
        "\n",
        "Apesar de que el modelo no llega al BLEU propuesto de 0.19, sí llega a un BLEU de aproximadamente 0.07-0.09. Como pudimos observar en las traducciones generadas por el modelo, se lograron traducir muy bien algunas oraciones, pero para otras se inventaba palabras o no traducía bien una palabra a su correspondiente en español; observamos que los detalles anteriores impactan significativamente en el score de BLUE, por lo que también lograr llegar a valor solicitado es un reto."
      ],
      "metadata": {
        "id": "FqzMtetYDCpn"
      }
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}

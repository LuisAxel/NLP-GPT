{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "NLyR9luRWsxI"
   },
   "outputs": [],
   "source": [
    "# The MIT License (MIT) Copyright (c) 2023 Emilio Morales\n",
    "#\n",
    "# Permission is hereby granted, free of charge, to any person obtaining a copy of\n",
    "# this software and associated documentation files (the \"Software\"), to deal in the Software without\n",
    "# restriction, including without limitation the rights to use, copy, modify, merge, publish,\n",
    "# distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the\n",
    "# Software is furnished to do so, subject to the following conditions:\n",
    "#\n",
    "# The above copyright notice and this permission notice shall be included in all copies or\n",
    "# substantial portions of the Software.\n",
    "#\n",
    "# THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED,\n",
    "# INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND\n",
    "# NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES\n",
    "# OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN\n",
    "# CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WqusX_h4WsxK"
   },
   "source": [
    "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/milmor/NLP/blob/main/Notebooks/13_RNN_LSTM.ipynb\">\n",
    "    <img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />\n",
    "    Run in Google Colab</a>\n",
    "  </td>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ty7Z3RRm2v0P"
   },
   "source": [
    "# NLP Programa 3: GPT  \n",
    "-------\n",
    "Integrantes:\n",
    "- Andrés Urbano Andrea\n",
    "- Núñez Quintana Luis Axel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0.- Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import keras_core as keras\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "import os\n",
    "import pandas as pd\n",
    "import pathlib\n",
    "import random\n",
    "from sklearn.decomposition import PCA\n",
    "import tensorflow as tf\n",
    "import time\n",
    "import torch\n",
    "from torch import optim\n",
    "import torch.nn as nn\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch.utils.data import DataLoader\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "from torchtext.vocab import vocab as Vocab\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' # Disable tensorflow debugging logs\n",
    "os.environ[\"KERAS_BACKEND\"] = \"torch\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x72605f9a6550>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__\n",
    "torch.manual_seed(77)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Disable warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YuZuE99sWsxO"
   },
   "source": [
    "## 1.- Conjuntos de entrenamiento y validación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dnlt2x--WsxV",
    "outputId": "570a1fc8-fc10-44ce-e06e-a23a7c88dca5",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def download_text_pairs():\n",
    "    path_to_zip = tf.keras.utils.get_file(\n",
    "        'spa-eng.zip', \n",
    "        origin='http://storage.googleapis.com/download.tensorflow.org/data/spa-eng.zip',\n",
    "        extract=True)\n",
    "    path_to_file = pathlib.Path(path_to_zip).parent/'spa-eng/spa.txt'\n",
    "    \n",
    "    with open(path_to_file) as f:\n",
    "        lines = f.read().split(\"\\n\")[:-1]\n",
    "        \n",
    "    text_pairs = []\n",
    "    for line in lines:\n",
    "        eng, spa = line.lower().split(\"\\t\")\n",
    "        text_pairs.append((eng, spa))\n",
    "    return text_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_text_pairs(text_pairs, val_percentage = 0.005, random_seed=43):\n",
    "    random.Random(random_seed).shuffle(text_pairs)\n",
    "    num_val_samples = int(val_percentage * len(text_pairs))\n",
    "    num_train_samples = len(text_pairs) - num_val_samples\n",
    "    train_pairs = text_pairs[:num_train_samples]\n",
    "    val_pairs = text_pairs[num_train_samples:]\n",
    "    return train_pairs, val_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "118964 total pairs\n",
      "118370 training pairs\n",
      "594 validation pairs\n",
      "('the old woman fell and could not get up.', 'la anciana se cayó y no pudo levantarse.')\n",
      "('what is this the abbreviation for?', '¿de qué es abreviatura esto?')\n",
      "(\"you're not sick.\", 'no estás enferma.')\n"
     ]
    }
   ],
   "source": [
    "text_pairs = download_text_pairs()\n",
    "train_pairs, val_pairs = split_text_pairs(text_pairs)\n",
    "\n",
    "print(f\"{len(text_pairs)} total pairs\")\n",
    "print(f\"{len(train_pairs)} training pairs\")\n",
    "print(f\"{len(val_pairs)} validation pairs\")\n",
    "\n",
    "for s in train_pairs[:3]:\n",
    "    print(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b4KjIrLz8Ryf",
    "outputId": "f4ace4f8-ec84-4556-cba5-87748562de3c"
   },
   "source": [
    "## 2.- Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NWW4RxWhpAZf"
   },
   "source": [
    "- Crea vocabulario y define tokenizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "0viwLWSUpGrk"
   },
   "outputs": [],
   "source": [
    "tokenizer = get_tokenizer('basic_english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "qpTS_ktRo_xd"
   },
   "outputs": [],
   "source": [
    "def build_vocab(eng_text, tokenizer, min_freq=5):\n",
    "    counter = Counter()\n",
    "    for eng_line in eng_text:\n",
    "        counter.update(tokenizer(eng_line))\n",
    "    return Vocab(counter, min_freq=min_freq,\n",
    "                 specials=['<unk>', '<pad>'])\n",
    "\n",
    "vocab = build_vocab([eng_text[0] for eng_text in text_pairs], tokenizer, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RlV0maHzt88t",
    "outputId": "df3f7b6e-9058-4a87-ffc7-45a360d2bdeb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5316"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size = len(vocab) + 1\n",
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "3wG0tHjuWsxa"
   },
   "outputs": [],
   "source": [
    "vocab.set_default_index(len(vocab)) # evita error <ukn>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Og1BFvJrWsxa",
    "outputId": "9dd04a1e-b7b3-4742-8303-7ee5f0e058fd",
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[46], line 14\u001b[0m\n\u001b[1;32m     11\u001b[0m             data\u001b[38;5;241m.\u001b[39mappend((tensor_, target_))\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m data\n\u001b[0;32m---> 14\u001b[0m train_data \u001b[38;5;241m=\u001b[39m data_process(\u001b[43mtrain_df\u001b[49m\u001b[38;5;241m.\u001b[39mtweet_text\u001b[38;5;241m.\u001b[39mvalues,\n\u001b[1;32m     15\u001b[0m                           train_df\u001b[38;5;241m.\u001b[39mcyberbullying_type\u001b[38;5;241m.\u001b[39mvalues)\n\u001b[1;32m     16\u001b[0m val_data \u001b[38;5;241m=\u001b[39m data_process(val_df\u001b[38;5;241m.\u001b[39mtweet_text\u001b[38;5;241m.\u001b[39mvalues,\n\u001b[1;32m     17\u001b[0m                         val_df\u001b[38;5;241m.\u001b[39mcyberbullying_type\u001b[38;5;241m.\u001b[39mvalues)\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28mlen\u001b[39m(train_data), \u001b[38;5;28mlen\u001b[39m(val_data)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_df' is not defined"
     ]
    }
   ],
   "source": [
    "maxlen = 64\n",
    "\n",
    "def data_process(x, y):\n",
    "    data = []\n",
    "    for raw_txt, target in zip(x, y):\n",
    "        tensor_ = torch.tensor([vocab[token] for token in tokenizer(raw_txt)],\n",
    "                        dtype=torch.long)\n",
    "        if tensor_.shape[0] <= maxlen:\n",
    "            # int64 to avoid CrossEntropyLoss \"expected scalar type Long but found Float\"\n",
    "            target_ = torch.tensor(target, dtype=torch.int64)\n",
    "            data.append((tensor_, target_))\n",
    "    return data\n",
    "\n",
    "train_data = data_process(train_df.tweet_text.values,\n",
    "                          train_df.cyberbullying_type.values)\n",
    "val_data = data_process(val_df.tweet_text.values,\n",
    "                        val_df.cyberbullying_type.values)\n",
    "len(train_data), len(val_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cW6E9jkJTe1o",
    "outputId": "c9b814fe-b035-4379-f7a7-f69e65317894"
   },
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "PAD_IDX = vocab['<pad>']\n",
    "\n",
    "def generate_batch(data_batch):\n",
    "    x, y = [], []\n",
    "    for (x_item, y_item) in data_batch:\n",
    "        x.append(x_item)\n",
    "        y.append(y_item)\n",
    "\n",
    "    x = pad_sequence(x, batch_first=True, padding_value=PAD_IDX)\n",
    "    # int64 to avoid CrossEntropyLoss \"expected scalar type Long but found Float\"\n",
    "    y = torch.tensor(y, dtype=torch.int64)\n",
    "    return x, y\n",
    "\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size=batch_size,\n",
    "                          shuffle=True, collate_fn=generate_batch,\n",
    "                          num_workers=4, pin_memory=True)\n",
    "val_loader = DataLoader(val_data, batch_size=batch_size,\n",
    "                        shuffle=True, collate_fn=generate_batch,\n",
    "                        num_workers=4, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "u_N6IRYsT4ry",
    "outputId": "35681e3f-5639-4b76-f7cb-32da7cb6cff4",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%timeit\n",
    "train_batch, target_batch = next(iter(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aauQX2tFXD8K"
   },
   "outputs": [],
   "source": [
    "train_batch, target_batch = next(iter(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ROw_9EjsT2Et",
    "outputId": "f5152bf2-ab07-43f8-f544-085ba9d58e23"
   },
   "outputs": [],
   "source": [
    "train_batch.shape, target_batch.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PZ7f4DHJreIj"
   },
   "source": [
    "## 3.- Modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M2Vv3PCUWsxd"
   },
   "source": [
    "### RNN simple\n",
    "\n",
    "RNN:\n",
    "\\begin{equation}\n",
    "h_t = f(Wx_t + Uh_{t-1} + b)\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CRwHxAuGYEKa",
    "outputId": "eb3a33d0-b56f-4c86-8c66-ffba3209fc82"
   },
   "outputs": [],
   "source": [
    "class Attention(nn.Module):\n",
    "    def __init__(self, dim, h):\n",
    "        super(Attention, self).__init__()\n",
    "        self.dim = dim\n",
    "        self.h = h\n",
    "        self.h_dim = int(dim/h)\n",
    "        self.scale = self.h_dim ** -0.5\n",
    "        self.wq = nn.Linear(dim, dim)\n",
    "        self.wk = nn.Linear(dim, dim)\n",
    "        self.wv = nn.Linear(dim, dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "      B, L, D = x.shape\n",
    "      q = self.wq(x)\n",
    "      k = self.wk(x)\n",
    "      v = self.wv(x)\n",
    "      q = q.reshape([B, L, self.h_dim, -1])\n",
    "      q = q.permute([0, 3, 1, 2])\n",
    "      k = k.reshape([B, L, self.h_dim, -1])\n",
    "      k = k.permute([0, 3, 2, 1])\n",
    "      v = v.reshape([B, L, self.h_dim, -1])\n",
    "      v = v.permute([0, 3, 1, 2])\n",
    "\n",
    "      qk = torch.matmul(q, k)\n",
    "      attn = torch.softmax(qk / self.scale, -1)\n",
    "      out = torch.matmul(attn, v).permute([0, 2, 1, 3])\n",
    "      out = out.reshape([B, L, -1])\n",
    "      return out\n",
    "\n",
    "b = torch.ones([2, 256, 16])\n",
    "a= Attention(16, 2)\n",
    "a(b).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TJmNuwH1clQd",
    "outputId": "806ce157-d0b0-4343-d069-2825e02feb09"
   },
   "outputs": [],
   "source": [
    "class TransformerBlock(nn.Module):\n",
    "    def __init__(self, dim, h):\n",
    "        super(TransformerBlock, self).__init__()\n",
    "        self.ln1 = torch.nn.LayerNorm(dim)\n",
    "        self.ln2 = torch.nn.LayerNorm(dim)\n",
    "        self.attn = Attention(dim, h)\n",
    "        self.mlp = torch.nn.Sequential(\n",
    "            nn.Linear(dim, dim),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(dim, dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, inp):\n",
    "      x = self.attn(inp) + inp\n",
    "      skip = self.ln1(x)\n",
    "      x = self.mlp(skip) + skip\n",
    "      x = self.ln2(x)\n",
    "      return x\n",
    "\n",
    "t=TransformerBlock(16, 2)\n",
    "t(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qJaYcsx0ef58",
    "outputId": "90d36f9f-e146-4d80-a9ba-ab4a6d12e7db"
   },
   "outputs": [],
   "source": [
    "class Transformer(nn.Module):\n",
    "    def __init__(self, vocab_size, maxlen, dim, h):\n",
    "        super(Transformer, self).__init__()\n",
    "        self.dim = dim\n",
    "        self.emb = nn.Embedding(vocab_size, dim)\n",
    "        self.pos = nn.Parameter(torch.rand(1, maxlen, dim))\n",
    "\n",
    "        self.transformer = nn.Sequential()\n",
    "\n",
    "        for _ in range(4):\n",
    "            self.transformer.append(\n",
    "                TransformerBlock(dim, h)\n",
    "            )\n",
    "\n",
    "        self.mlp_head=torch.nn.Sequential(\n",
    "            torch.nn.LayerNorm(dim),\n",
    "            nn.Linear(dim, 6)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        B, L = x.shape\n",
    "        x = self.emb(x) + self.pos[:, L, :]\n",
    "        x = self.transformer(x)\n",
    "        x = self.mlp_head(x[:,  -1, :])\n",
    "        return x\n",
    "\n",
    "trans =Transformer(9952, 64+1, 64, 2)\n",
    "trans(train_batch).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "D01PZJVbWsxe",
    "outputId": "1485661b-981c-4796-c4bc-1c68ed7279a0"
   },
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self, vocab_size):\n",
    "        super(RNN, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, 128)\n",
    "        self.rnn = nn.RNN(input_size=128,\n",
    "                        hidden_size=128,\n",
    "                        num_layers=1,\n",
    "                        batch_first=True)\n",
    "        self.fc1 = nn.Linear(128, 16)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(16, 16)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.fc3 = nn.Linear(16, 6)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)\n",
    "        x, hidden = self.rnn(x)\n",
    "        x = x[:, -1, :]\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.relu2(x)\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "rnn = RNN(vocab_size)\n",
    "output_batch = rnn(train_batch)\n",
    "output_batch.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "87-0prZUWsxe"
   },
   "source": [
    "### LSTM\n",
    "\n",
    "LSTM:\n",
    "\n",
    "\\begin{align}\n",
    "i_t & = \\sigma(W^ix_t + U^ih_{t-1} + b^i) \\\\\n",
    "f_t & = \\sigma(W^fx_t + U^fh_{t-1} + b^f) \\\\\n",
    "o_t & = \\sigma(W^ox_t + U^oh_{t-1} + b^o) \\\\\n",
    "g_t & = \\text{tanh}(W^gx_t + U^gh_{t-1} + b^g) \\\\\n",
    "c_t & = f_t \\odot c_{t-1} + i_t \\odot g_t\\\\\n",
    "h_t & = o_t \\odot \\text{tanh}(c_t) \\\\\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "t2ndlTvDWsxf",
    "outputId": "7fdf146c-9fef-4a86-d7cf-356489df232a"
   },
   "outputs": [],
   "source": [
    "class LSTM(nn.Module):\n",
    "    def __init__(self, vocab_size):\n",
    "        super(LSTM, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, 128)\n",
    "        self.lstm = nn.LSTM(input_size=128,\n",
    "                        hidden_size=128,\n",
    "                        num_layers=1,\n",
    "                        batch_first=True)\n",
    "        self.fc1 = nn.Linear(128, 16)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(16, 16)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.fc3 = nn.Linear(16, 6)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)\n",
    "        x, (hidden, cell) = self.lstm(x)\n",
    "        x = x[:, -1, :]\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.relu2(x)\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "lstm = LSTM(vocab_size)\n",
    "output_batch = lstm(train_batch)\n",
    "output_batch.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MsJbLyZ6b_57"
   },
   "source": [
    "## 4.- Entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FwlOLQfvWsxg"
   },
   "outputs": [],
   "source": [
    "loss_fn = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "R5bmAldOcJn0"
   },
   "outputs": [],
   "source": [
    "def train(model, device, train_loader, optimizer, epoch):\n",
    "    start = time.time()\n",
    "    running_loss = 0.0\n",
    "    model.train()\n",
    "    for inputs, labels in train_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = model(inputs)\n",
    "        outputs = outputs.squeeze()\n",
    "        loss = loss_fn(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    print(f'\\nTime for epoch {epoch} is {time.time()-start:.4f} sec Train loss: {running_loss / len(train_loader):.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xwUH9ZlHWsxh"
   },
   "outputs": [],
   "source": [
    "def test(model, device, test_loader):\n",
    "    start = time.time()\n",
    "    running_loss = 0.0\n",
    "    running_acc = 0.0\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        for inputs, labels in test_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            outputs = outputs.squeeze()\n",
    "            loss = loss_fn(outputs, labels)\n",
    "            _, pred = torch.max(outputs.data, 1)\n",
    "            running_acc += (pred == labels).sum().item()\n",
    "            running_loss += loss.item()\n",
    "\n",
    "    print(f'Time for eval is {time.time()-start:.4f} sec Val loss: {running_loss / len(test_loader):.4f}')\n",
    "    print(f'Val acc: {running_acc / len(test_loader.dataset):.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EvsuJHMBlm9y",
    "outputId": "4e6da109-4c05-4629-c327-a37fbc684b9e"
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wl9MQCp9TLCh"
   },
   "outputs": [],
   "source": [
    "trans.to(device)\n",
    "\n",
    "trans_optimizer = optim.Adam(trans.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gtR1RoSBkARg",
    "outputId": "1174ca9d-424a-49f3-c85f-854ef374553d",
    "tags": []
   },
   "outputs": [],
   "source": [
    "epochs = 7\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    train(trans, device, train_loader, trans_optimizer, epoch)\n",
    "    test(trans, device, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OMpi1vCYWsxj"
   },
   "outputs": [],
   "source": [
    "lstm.to(device)\n",
    "\n",
    "lstm_optimizer = optim.Adam(lstm.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SMHJlSRSWsxj",
    "outputId": "41cb5a73-39a0-42fa-859e-15c6fed69c82",
    "tags": []
   },
   "outputs": [],
   "source": [
    "epochs = 7\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    train(lstm, device, train_loader, lstm_optimizer, epoch)\n",
    "    test(lstm, device, val_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nsDNasoTWsxk"
   },
   "source": [
    "## 5.- Vectores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "98dIk1jlWsxk",
    "outputId": "e9e027ea-1f73-46c4-fc43-3f5ef58bfbc3",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "words = 'bad good hate happy love scared friend sad alive family confident fight live funny best great amazing'\n",
    "words_ids = torch.tensor([vocab[token] for token in tokenizer(words)])\n",
    "words_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EaBvtO58Wsxl",
    "outputId": "ca33b5c7-2504-4cff-a4c7-8f17f396ae8d"
   },
   "outputs": [],
   "source": [
    "lstm.to('cpu')\n",
    "lstm.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pEjmNgV5Wsxl",
    "outputId": "9bbde439-d557-4bc4-f7c8-2b8c6e4a4429"
   },
   "outputs": [],
   "source": [
    "embeddings = lstm.embedding(words_ids).detach()\n",
    "embeddings.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QfUA35tAWsxm"
   },
   "source": [
    "- Visualización de los vectores aprendidos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 448
    },
    "id": "sUehSDqlWsxm",
    "outputId": "f2d3eeb6-6928-4bb9-cd1f-367a55f213ef"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "\n",
    "# Perform PCA on embeddings\n",
    "pca = PCA(n_components=2)\n",
    "pca_embeddings = pca.fit_transform(embeddings)\n",
    "print(pca_embeddings.shape)\n",
    "\n",
    "# Plot embeddings using matplotlib\n",
    "fig, ax = plt.subplots()\n",
    "ax.scatter(pca_embeddings[:, 0], pca_embeddings[:, 1], marker='o', c='b')\n",
    "\n",
    "for i, word in enumerate(words.split()):\n",
    "    ax.annotate(word, (pca_embeddings[i, 0], pca_embeddings[i, 1]))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.- Evaluación (BLEU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bleu_example():\n",
    "    # Lista de oraciones de referencia (lista de listas)\n",
    "    referencias = [['El', 'gato', 'está', 'en', 'la', 'alfombra'],\n",
    "                   ['El', 'perro', 'juega', 'en', 'el', 'parque'],\n",
    "                   ['El', 'cielo', 'está', 'despejado'],\n",
    "                   ['El', 'sol', 'brilla', 'intensamente'],\n",
    "                   ['Los', 'pájaros', 'cantan', 'en', 'los', 'árboles']]\n",
    "    \n",
    "    # Lista de oraciones candidatas (lista de listas)\n",
    "    candidatas = [['El', 'gato', 'está', 'durmiendo', 'en', 'la', 'alfombra'],\n",
    "                  ['El', 'perro', 'juega', 'en', 'el', 'jardín'],\n",
    "                  ['El', 'cielo', 'está', 'soleado'],\n",
    "                  ['El', 'sol', 'brilla', 'intensamente'],\n",
    "                  ['Los', 'pájaros', 'trinan', 'en', 'los', 'árboles']]\n",
    "    \n",
    "    # Calcular el BLEU score para cada oración candidata\n",
    "    for i in range(len(candidatas)):\n",
    "        referencia = referencias[i]\n",
    "        candidata = candidatas[i]\n",
    "        \n",
    "        bleu_score = nltk.translate.bleu_score.sentence_bleu([referencia], candidata)\n",
    "        print(f\"BLEU score para la oración {i+1}: {bleu_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU score para la oración 1: 8.44484326442819e-78\n",
      "BLEU score para la oración 2: 0.7598356856515925\n",
      "BLEU score para la oración 3: 8.636168555094496e-78\n",
      "BLEU score para la oración 4: 1.0\n",
      "BLEU score para la oración 5: 7.262123179505913e-78\n"
     ]
    }
   ],
   "source": [
    "bleu_example()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

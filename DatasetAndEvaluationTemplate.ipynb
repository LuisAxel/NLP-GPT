{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "O00JdIwIRZ_U",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using PyTorch backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' # Disable tensorflow debugging logs\n",
    "os.environ[\"KERAS_BACKEND\"] = \"torch\"\n",
    "import keras_core as keras\n",
    "import tensorflow as tf\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.- Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pathlib\n",
    "\n",
    "path_to_zip = tf.keras.utils.get_file(\n",
    "    'spa-eng.zip', origin='http://storage.googleapis.com/download.tensorflow.org/data/spa-eng.zip',\n",
    "    extract=True)\n",
    "path_to_file = pathlib.Path(path_to_zip).parent/'spa-eng/spa.txt'\n",
    "\n",
    "with open(path_to_file) as f:\n",
    "    lines = f.read().split(\"\\n\")[:-1]\n",
    "    \n",
    "text_pairs = []\n",
    "for line in lines:\n",
    "    eng, spa = line.lower().split(\"\\t\")\n",
    "    text_pairs.append((eng, spa))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "118964 total pairs\n",
      "118370 training pairs\n",
      "594 validation pairs\n"
     ]
    }
   ],
   "source": [
    "random.Random(43).shuffle(text_pairs)\n",
    "num_val_samples = int(0.005 * len(text_pairs))\n",
    "num_train_samples = len(text_pairs) - num_val_samples\n",
    "train_pairs = text_pairs[:num_train_samples]\n",
    "val_pairs = text_pairs[num_train_samples:]\n",
    "\n",
    "print(f\"{len(text_pairs)} total pairs\")\n",
    "print(f\"{len(train_pairs)} training pairs\")\n",
    "print(f\"{len(val_pairs)} validation pairs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('the old woman fell and could not get up.', 'la anciana se cayó y no pudo levantarse.')\n",
      "('what is this the abbreviation for?', '¿de qué es abreviatura esto?')\n",
      "(\"you're not sick.\", 'no estás enferma.')\n",
      "('i have no knife to cut with.', 'no tengo un cuchillo con que cortarlo.')\n",
      "('americans admire lincoln for his honesty.', 'los estadounidenses admiran a lincoln por su honestidad.')\n"
     ]
    }
   ],
   "source": [
    "for s in train_pairs[:5]:\n",
    "    print(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.- Evaluación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "# Disable warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU score para la oración 1: 8.44484326442819e-78\n",
      "BLEU score para la oración 2: 0.7598356856515925\n",
      "BLEU score para la oración 3: 8.636168555094496e-78\n",
      "BLEU score para la oración 4: 1.0\n",
      "BLEU score para la oración 5: 7.262123179505913e-78\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "# Lista de oraciones de referencia (lista de listas)\n",
    "referencias = [['El', 'gato', 'está', 'en', 'la', 'alfombra'],\n",
    "               ['El', 'perro', 'juega', 'en', 'el', 'parque'],\n",
    "               ['El', 'cielo', 'está', 'despejado'],\n",
    "               ['El', 'sol', 'brilla', 'intensamente'],\n",
    "               ['Los', 'pájaros', 'cantan', 'en', 'los', 'árboles']]\n",
    "\n",
    "# Lista de oraciones candidatas (lista de listas)\n",
    "candidatas = [['El', 'gato', 'está', 'durmiendo', 'en', 'la', 'alfombra'],\n",
    "              ['El', 'perro', 'juega', 'en', 'el', 'jardín'],\n",
    "              ['El', 'cielo', 'está', 'soleado'],\n",
    "              ['El', 'sol', 'brilla', 'intensamente'],\n",
    "              ['Los', 'pájaros', 'trinan', 'en', 'los', 'árboles']]\n",
    "\n",
    "# Calcular el BLEU score para cada oración candidata\n",
    "for i in range(len(candidatas)):\n",
    "    referencia = referencias[i]\n",
    "    candidata = candidatas[i]\n",
    "    \n",
    "    bleu_score = nltk.translate.bleu_score.sentence_bleu([referencia], candidata)\n",
    "    print(f\"BLEU score para la oración {i+1}: {bleu_score}\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "text_generation_with_miniature_gpt",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
